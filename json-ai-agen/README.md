# ğŸŒŸ **JSON-AI-Agent: Your AI Sidekick for JSON and Weather Data** ğŸŒŸ


This code creates an AI agent that can generate JSON objects (like PokÃ©mon cards!) and interact with external APIs (like a weather API) to provide useful information. It leverages the power of large language models (LLMs) from OpenAI (using the Together API for access) to understand natural language prompts and respond intelligently.

## âœ¨ **Key Features & How it Works** âœ¨

1. **JSON Generation** ğŸ¤–
    *   **PokÃ©mon Power!** âš¡ï¸: The code starts by defining a `schema` for a PokÃ©mon card (name, type, HP).
    *   **LLM Magic**: It then uses an LLM (Meta-Llama-3.1-70B-Instruct-Turbo) to generate new PokÃ©mon cards in JSON format based on this schema.
    *   **Example**:

        ```json
        {
          "name": "Embermaw",
          "type": "Fire/Dragon",
          "HP": 120
        }
        ```

2. **Tool Use: Expanding the Agent's Abilities** ğŸ› ï¸
    *   **Function Calling**: The agent is equipped with "tools" â€“ functions it can call to perform specific tasks.
    *   **Defined Tools**:
        *   `calculator`: For math problems (not fully implemented in this example, but the structure is there).
        *   `check_weather`: To fetch weather data.

3. **Weather Wizardry** â˜€ï¸ğŸŒ§ï¸
    *   **Weather API Integration**: The `get_weather` function uses the `weatherapi.com` API to retrieve current weather data for a given city.
    *   **API Key**: You'll need to sign up for a free API key from `weatherapi.com` and store it as `WEATHER_API_KEY` in your Colab environment using `google.colab.userdata`.
    *   **Example Output**:
        ```json
         {
           'location': {'name': 'Karachi', 'region': 'Sindh', 'country': 'Pakistan', ...},
           'current': {'last_updated': '2025-01-30 23:30', 'temp_c': 18.3, 'temp_f': 64.9, 'condition': {'text': 'Mist', ...}, ...}
         }
        ```

4. **Conversational AI: Putting it All Together** ğŸ§ ğŸ’¬
    *   **Chat History**: The `chat_history` list stores the conversation between the user and the AI.
    *   **Interactive Loop**: The `while True` loop is the heart of the agent:
        1. **Prompt the LLM**: Sends the `chat_history` to the LLM (Llama-3.3-70B-Instruct-Turbo-Free) along with the available `tools`.
        2. **Tool Calls**: If the LLM decides to use a tool, it provides the function name and arguments in `tool_calls`.
        3. **Execute Tool**: The code extracts the arguments, calls the appropriate function (e.g., `get_weather`), and appends the result to the `chat_history`.
        4. **LLM Response**: If no tool is called, the LLM's response is directly printed.
    *   **Example Conversation**:
        *   **User**: "What's the weather in France today?"
        *   **Agent** (after calling `check_weather` for Paris): "The weather in Paris, France today is partly cloudy with a temperature of 6.3Â°C (43.3Â°F)..."

## ğŸš€ **Code Highlights with Emojis** ğŸš€

### **1. Setting up the LLM Client**

```python
from openai import OpenAI
from google.colab import userdata

client= OpenAI(
    api_key=userdata.get('TOGETHER_API_KEY_NEW'),  # ğŸ”‘ Your API key from Together
    base_url='https://api.together.xyz/v1'      # ğŸŒ Together API endpoint
)
```

### **2. Generating a PokÃ©mon Card**

```python
completion = client.chat.completions.create(
    model="meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo", # ğŸ§  Powerful LLM
    messages=[
        {"role": "user",
         "content": "Generate a pokemon card. use JSON, and awlwys respones in this format: "}], # ğŸ“ Prompt
  response_format={"type": "json_object", "schema": schema} #  à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ

)

print(completion.choices[0].message.content) # ğŸ–¨ï¸ Print the JSON
```

### **3. Defining Tools**

```python
tools = [{
    "type": "function",
    "function": {
        "name": "calculator", # ğŸ§® Name of the tool
        "description": "Useful for when you need to answer questions about math.", # â„¹ï¸ Description
        "parameters": { # âš™ï¸ Parameters for the tool
            "type": "object",
            "properties": {
                "expression": { "type": "string" }
            }
        }
    }
}, {
    "type": "function",
    "function": {
        "name": "check_weather", # ğŸŒ¦ï¸ Name of the tool
        "description": "Useful for when you need to check the weather!", # â„¹ï¸ Description
        "parameters": {
            "type": "object",
            "properties": {
                "city_name": { "type": "string", "description": "The name of a city NOT a country" } # ğŸ™ï¸ City parameter
            }
        }
    }
}]
```

### **4. Getting Weather Data**

```python
import requests

def get_weather(city):
  api_key = userdata.get('WEATHER_API_KEY') # ğŸ”‘ Your Weather API key
  url = f"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city}&aqi=no" # ğŸŒ API URL
  response = requests.get(url) # ğŸ“¡ Make the API request
  weather_data = response.json() # â¡ï¸ JSON response
  return weather_data
```

### **5. The Main Loop**

```python
import json

chat_history=[
    {
        "role": "user",
        "content": "What's the weather in France today?"
    }
  ] # ğŸ’¬ Initial conversation

while True: # ğŸ” Keep going until break

  completion = client.chat.completions.create(
    model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free", # ğŸ§  LLM model
    messages=chat_history, # ğŸ“œ Send the conversation history
    tools=tools # ğŸ› ï¸ Provide the tools
  )

  tool_calls = completion.choices[0].message.tool_calls # ğŸ“ Check for tool calls

  if tool_calls:
    arguments = tool_calls[0].function.arguments # ğŸ“„ Get arguments
    print(arguments)
    name = tool_calls[0].function.name # ğŸ§° Get tool name
    print(name)

    chat_history.append(completion.choices[0].message) # â• Add LLM message to history

    if name == "check_weather": # ğŸŒ¦ï¸ If it's the weather tool
      city = json.loads(arguments)["city_name"] # ğŸ™ï¸ Get the city
      weather_data = get_weather(city) # â¡ï¸ Get weather data
      chat_history.append({ # â• Add weather data to history
          "role": "function",
          "name": name,
          "content": json.dumps(weather_data)
      })
  else:
    print(completion.choices[0].message.content) # ğŸ–¨ï¸ Print the LLM's response
    break # ğŸ›‘ Exit the loop
```

## ğŸ‰ **Conclusion** ğŸ‰

This code demonstrates a powerful and flexible way to build AI agents that can interact with the real world through APIs and provide valuable information in a structured format like JSON. You can expand upon this example by adding more tools, refining the prompts, and even integrating it into a larger application. Have fun exploring the possibilities!
